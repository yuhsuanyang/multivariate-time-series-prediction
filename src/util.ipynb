{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model,feature,label,batch,opt,train,loss_func,device): \n",
    "    total_loss=0\n",
    "    start=0\n",
    "    for j in range(int(len(feature)/batch)+1):\n",
    "        if start+batch>len(feature):\n",
    "            end=-1\n",
    "        else:\n",
    "            end=start+batch\n",
    "            \n",
    "        x=feature[start:end].to(device) #x,y放到gpu裡\n",
    "        y=label[start:end].to(device)\n",
    "        out=model(x)\n",
    "        out=out.to(device)\n",
    "        loss=loss_func(out,y)\n",
    "        if train:\n",
    "            opt.zero_grad() #梯度歸零\n",
    "            loss.backward() #back propogation\n",
    "            opt.step() #更新參數\n",
    "        #print('batch loss:'+str(loss.item()))\n",
    "        total_loss+=loss.item()\n",
    "        torch.cuda.empty_cache()\n",
    "        start=end\n",
    "    total_loss=total_loss/(int(len(feature)/batch)+1)\n",
    "    return total_loss\n",
    "\n",
    "def mape(prediction,truth,M,m):\n",
    "    diff=(prediction-truth).detach().numpy()*M\n",
    "    diff=np.absolute(diff/(truth.detach().numpy()*M+m))\n",
    "    return diff.mean()\n",
    "\n",
    "\n",
    "def mae(prediction, truth):\n",
    "    diff=np.absolute((prediction-truth).detach().numpy())\n",
    "    return diff.mean()\n",
    "\n",
    "\n",
    "def plot_result(xs,ys,output_len,title,target_series):\n",
    "    result=[]\n",
    "    truth=[]\n",
    "    for i in range(2):\n",
    "        for j in range(0,xs[i].shape[0],output_len):\n",
    "            prediction=model(xs[i][j].unsqueeze(0))[:,:,0].squeeze(0).tolist()\n",
    "            y=ys[i][j,:,0].tolist()\n",
    "        \n",
    "            result.extend([k*(scale[0][target_series]-scale[1][target_series])+scale[1][target_series] for k in prediction])\n",
    "            truth.extend([k*(scale[0][target_series]-scale[1][target_series])+scale[1][target_series] for k in y])\n",
    "        \n",
    "    plt.plot(truth)\n",
    "    plt.plot(result,alpha=0.5)\n",
    "    plt.legend(['truth','prediction'])\n",
    "    plt.title(title)\n",
    "    #plt.savefig(title+'.png')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    return result,truth\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def train(target, epochs, input_dim, input_len, output_len, split, model,constrain=False):\n",
    "    testing_mae=0\n",
    "    testing_mape=0\n",
    "    \n",
    "    #for i in targets:\n",
    "    print(data.columns[target])\n",
    "    rank=np.argsort(corr[:,i])[::-1]\n",
    "    \n",
    "    dataset1,dataset2=make_io(input_len,output_len,rank[0:input_dim],split)\n",
    "    dataset3,dataset4=make_io(input_len,output_len,rank[0:input_dim],split,False)\n",
    "\n",
    "    X_train=torch.FloatTensor(dataset1[0])\n",
    "    Y_train=torch.FloatTensor(dataset1[1])[:,:,0].unsqueeze(2)\n",
    "    S_train=torch.FloatTensor(dataset1[2])\n",
    "\n",
    "    X_test=torch.FloatTensor(dataset2[0])\n",
    "    Y_test=torch.FloatTensor(dataset2[1])[:,:,0].unsqueeze(2)\n",
    "    S_test=torch.FloatTensor(dataset2[2])\n",
    "\n",
    "    X_train_valid=torch.FloatTensor(dataset3[0])\n",
    "    Y_train_valid=torch.FloatTensor(dataset3[1])[:,:,0].unsqueeze(2)\n",
    "    S_train_valid=torch.FloatTensor(dataset3[2])\n",
    "\n",
    "    X_test_valid=torch.FloatTensor(dataset4[0])\n",
    "    Y_test_valid=torch.FloatTensor(dataset4[1])[:,:,0].unsqueeze(2)\n",
    "    S_test_valid=torch.FloatTensor(dataset4[2])\n",
    "        \n",
    "    model.to(gpu) #model放到gpu裡\n",
    "    print(count_parameters(model))\n",
    "    \n",
    "    for j in range(epochs):\n",
    "        if j<500:\n",
    "            rate=0.001\n",
    "        elif j>500 and j<2000:\n",
    "            rate=0.0001\n",
    "        else:\n",
    "            rate=0.00001\n",
    "            \n",
    "        opt=torch.optim.Adam(model.parameters(),lr=rate)\n",
    "        \n",
    "        if constrain:\n",
    "            model.weight.data.clamp_(0,1)\n",
    "   \n",
    "        training_loss=compute_loss(model,X_train,Y_train,batch,opt,train=True,device=gpu)\n",
    "        testing_loss=compute_loss(model,X_test,Y_test,batch,opt,train=False,device=gpu)\n",
    "        test_mape=mape(model(X_test.to(gpu))[:,:,0].to(cpu),Y_test[:,:,0],(scale[0][i]-scale[1][i]),scale[1][i])\n",
    "        \n",
    "        if j%100==0:\n",
    "            print('epoch:'+str(j))\n",
    "            print('training mae loss:'+str(training_loss))\n",
    "            print('testing mae loss:'+str(testing_loss))\n",
    "            print('testing mape:'+str(test_mape))\n",
    "            if constrain:\n",
    "                print(model.weight.data)\n",
    "            \n",
    "    model.to(cpu)        \n",
    "    #    testing_mae+=testing_loss\n",
    "    #    testing_mape+=mape(model(X_test)[:,:,0],Y_test[:,:,0],(scale[0][i]-scale[1][i]),scale[1][i])\n",
    "    plot_result([X_train_valid,X_test_valid],[Y_train_valid,Y_test_valid],7,data.columns[i],i)\n",
    "    \n",
    "    return X_train_valid, X_test_valid, rank\n",
    "    #print('testing mae:')\n",
    "    #print(testing_mae/len(targets))\n",
    "    #print('testing mape:')\n",
    "    #print(testing_mape/len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(model, X_train, X_test, title_name):\n",
    "    weights=[]\n",
    "    for i in range(len(X_train)):\n",
    "        _,_,sample=model.encoder(X_train[i].unsqueeze(0))\n",
    "        weights.append(sample[0][0].tolist())\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        _,_,sample=model.encoder(X_test[i].unsqueeze(0))\n",
    "        weights.append(sample[0][0].tolist())    \n",
    "        \n",
    "    w=np.array(weights).transpose()\n",
    "    w.shape\n",
    "    plt.pcolor(w)\n",
    "    plt.yticks([i for i in range(6)],[data.columns[i] for i in rank[1:]])\n",
    "    plt.title(title_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
